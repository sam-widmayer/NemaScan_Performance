---
title: "Polygenic Architectures are Difficult to Resolve Using GWAS"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
editor_options:
  chunk_output_type: console
---
```{r setup, message=FALSE, warning=FALSE, include=FALSE}
require(tidyverse)
require(tidymodels)
require(nationalparkcolors)
require(RColorBrewer)
require(workflowr)
require(viridis)
require(wesanderson)
require(data.table)
```

### Analysis date: `r format(Sys.time(), '%B %d, %Y')`

```{r message=FALSE, warning=FALSE, include=FALSE}
setwd("~/Documents/projects/NemaScan_Performance/") # Lab Computer
# setwd("~/Documents/AndersenLab/NemaScan_Performance/") # Laptop

# Dual Algorithm Aggregated Mapping Results: Default settings: Group = 1000 bp, CI = +150 markers
load(file = "data/NemaScan_Performance.Architecture.Mixed.v2.20210310.RData")

#####
dat.group1000.150.aggregate <- simulation.metrics.df %>%
  tidyr::separate(col = sim,
                  into = c("nQTL","Rep","h2","MAF","effect_range","strain_set"), 
                  sep = "_", remove = F) %>%
  tidyr::separate(col = QTL,
                  into = c("CHROM","POS"), 
                  sep = ":", remove = F) %>%
  dplyr::mutate(h2 = as.factor(h2),
                nQTL = as.factor(nQTL),
                POS = as.numeric(POS),
                startPOS = as.numeric(startPOS),
                peakPOS = as.numeric(peakPOS),
                endPOS = as.numeric(endPOS),
                interval.var.exp  = as.numeric(interval.var.exp),
                Simulated.QTL.VarExp = as.numeric(Simulated.QTL.VarExp), 
                peak_id = as.numeric(peak_id),
                BETA = as.numeric(BETA),
                Effect = as.numeric(Effect),
                Frequency = as.numeric(Frequency),
                log10p = dplyr::if_else(Simulated == FALSE, true = interval.log10p, false = log10p), # false discoveries inherit the log10p value of the peak marker for the interval
                log10p = as.numeric(log10p),
                interval_size = as.numeric(interval_size),
                aboveBF = dplyr::case_when(aboveBF == 1 ~ TRUE, 
                                           aboveBF == 0 ~ FALSE,
                                           is.na(aboveBF) ~ TRUE), # false discoveries by definition exceed significance threshold
                aboveBF = as.factor(aboveBF)) %>%
  dplyr::filter(!c(Detected == FALSE & aboveBF == TRUE),
                CHROM != 7)
dat.group1000.150.aggregate$nQTL <- factor(dat.group1000.150.aggregate$nQTL, levels = c("1","5","10","25"))
dat.group1000.150.aggregate$group.size <- as.factor(1000)
dat.group1000.150.aggregate$CI <- as.factor(150)
dat.group1000.150.aggregate$eval.method <- "Joint"
dat.group1000.150.aggregate$aboveBF <- factor(dat.group1000.150.aggregate$aboveBF, levels = c("TRUE","FALSE"))
dat.group1000.150.aggregate$vcf <- "20200815"
#####

# Dual Algorithm Aggregated Mapping Results: Default settings: Group = 1000 bp, CI = +150 markers
load(file = "data/NemaScan_Performance.Architecture.Mixed.WI.20210121.20210318.RData")
dat.group1000.150.aggregate.WI <- simulation.metrics.df %>%
  tidyr::separate(col = sim,
                  into = c("nQTL","Rep","h2","MAF","effect_range","strain_set"), 
                  sep = "_", remove = F) %>%
  tidyr::separate(col = QTL,
                  into = c("CHROM","POS"), 
                  sep = ":", remove = F) %>%
  dplyr::mutate(h2 = as.factor(h2),
                nQTL = as.factor(nQTL),
                POS = as.numeric(POS),
                startPOS = as.numeric(startPOS),
                peakPOS = as.numeric(peakPOS),
                endPOS = as.numeric(endPOS),
                interval.var.exp  = as.numeric(interval.var.exp),
                Simulated.QTL.VarExp = as.numeric(Simulated.QTL.VarExp), 
                peak_id = as.numeric(peak_id),
                BETA = as.numeric(BETA),
                Effect = as.numeric(Effect),
                Frequency = as.numeric(Frequency),
                log10p = dplyr::if_else(Simulated == FALSE, true = interval.log10p, false = log10p), # false discoveries inherit the log10p value of the peak marker for the interval
                log10p = as.numeric(log10p),
                interval_size = as.numeric(interval_size),
                aboveBF = dplyr::case_when(aboveBF == 1 ~ TRUE, 
                                           aboveBF == 0 ~ FALSE,
                                           is.na(aboveBF) ~ TRUE), # false discoveries by definition exceed significance threshold
                aboveBF = as.factor(aboveBF)) %>%
  dplyr::filter(!c(Detected == FALSE & aboveBF == TRUE),
                CHROM != 7)
dat.group1000.150.aggregate.WI$nQTL <- factor(dat.group1000.150.aggregate.WI$nQTL, levels = c("1","5","10","25"))
dat.group1000.150.aggregate.WI$group.size <- as.factor(1000)
dat.group1000.150.aggregate.WI$CI <- as.factor(150)
dat.group1000.150.aggregate.WI$eval.method <- "Joint"
dat.group1000.150.aggregate.WI$aboveBF <- factor(dat.group1000.150.aggregate.WI$aboveBF, levels = c("TRUE","FALSE"))
dat.group1000.150.aggregate.WI$vcf <- "20210121"


# Group = 500 bp, CI = +150 markers
load(file = "data/NemaScan_Performance.Architecture.Mixed.group500.v2.20210312.RData") #
#####
dat.group500.150.aggregate <- simulation.metrics.df %>%
  tidyr::separate(col = sim,
                  into = c("nQTL","Rep","h2","MAF","effect_range","strain_set"), 
                  sep = "_", remove = F) %>%
  tidyr::separate(col = QTL,
                  into = c("CHROM","POS"), 
                  sep = ":", remove = F) %>%
  dplyr::mutate(h2 = as.factor(h2),
                nQTL = as.factor(nQTL),
                POS = as.numeric(POS),
                startPOS = as.numeric(startPOS),
                peakPOS = as.numeric(peakPOS),
                endPOS = as.numeric(endPOS),
                interval.var.exp  = as.numeric(interval.var.exp),
                Simulated.QTL.VarExp = as.numeric(Simulated.QTL.VarExp), 
                peak_id = as.numeric(peak_id),
                BETA = as.numeric(BETA),
                Effect = as.numeric(Effect),
                Frequency = as.numeric(Frequency),
                log10p = dplyr::if_else(Simulated == FALSE, true = interval.log10p, false = log10p), # false discoveries inherit the log10p value of the peak marker for the interval
                log10p = as.numeric(log10p),
                interval_size = as.numeric(interval_size),
                aboveBF = dplyr::case_when(aboveBF == 1 ~ TRUE, 
                                           aboveBF == 0 ~ FALSE,
                                           is.na(aboveBF) ~ TRUE), # false discoveries by definition exceed significance threshold
                aboveBF = as.factor(aboveBF)) %>%
  dplyr::filter(!c(Detected == FALSE & aboveBF == TRUE),
                CHROM != 7)
dat.group500.150.aggregate$nQTL <- factor(dat.group500.150.aggregate$nQTL, levels = c("1","5","10","25"))
dat.group500.150.aggregate$group.size <- as.factor(500)
dat.group500.150.aggregate$CI <- as.factor(150)
#####




# Group = 1000 bp, CI = +50 markers
load(file = "data/NemaScan_Performance.Architecture.Mixed.CI50.v2.20210312.RData")
#####

dat.group1000.50.aggregate <- simulation.metrics.df %>%
  tidyr::separate(col = sim,
                  into = c("nQTL","Rep","h2","MAF","effect_range","strain_set"), 
                  sep = "_", remove = F) %>%
  tidyr::separate(col = QTL,
                  into = c("CHROM","POS"), 
                  sep = ":", remove = F) %>%
  dplyr::mutate(h2 = as.factor(h2),
                nQTL = as.factor(nQTL),
                POS = as.numeric(POS),
                startPOS = as.numeric(startPOS),
                peakPOS = as.numeric(peakPOS),
                endPOS = as.numeric(endPOS),
                interval.var.exp  = as.numeric(interval.var.exp),
                Simulated.QTL.VarExp = as.numeric(Simulated.QTL.VarExp), 
                peak_id = as.numeric(peak_id),
                BETA = as.numeric(BETA),
                Effect = as.numeric(Effect),
                Frequency = as.numeric(Frequency),
                log10p = dplyr::if_else(Simulated == FALSE, true = interval.log10p, false = log10p), # false discoveries inherit the log10p value of the peak marker for the interval
                log10p = as.numeric(log10p),
                interval_size = as.numeric(interval_size),
                aboveBF = dplyr::case_when(aboveBF == 1 ~ TRUE, 
                                           aboveBF == 0 ~ FALSE,
                                           is.na(aboveBF) ~ TRUE), # false discoveries by definition exceed significance threshold
                aboveBF = as.factor(aboveBF)) %>%
  dplyr::filter(!c(Detected == FALSE & aboveBF == TRUE),
                CHROM != 7)
dat.group1000.50.aggregate$nQTL <- factor(dat.group1000.50.aggregate$nQTL, levels = c("1","5","10","25"))
dat.group1000.50.aggregate$group.size <- as.factor(1000)
dat.group1000.50.aggregate$CI <- as.factor(50)
#####

# Group = 500 bp, CI = +50 markers
load(file = "data/NemaScan_Performance.Architecture.Mixed.CI50.group500.v2.20210312.RData")
#####
 # Architecture Sims
dat.group500.50.aggregate <- simulation.metrics.df %>%
  tidyr::separate(col = sim,
                  into = c("nQTL","Rep","h2","MAF","effect_range","strain_set"), 
                  sep = "_", remove = F) %>%
  tidyr::separate(col = QTL,
                  into = c("CHROM","POS"), 
                  sep = ":", remove = F) %>%
  dplyr::mutate(h2 = as.factor(h2),
                nQTL = as.factor(nQTL),
                POS = as.numeric(POS),
                startPOS = as.numeric(startPOS),
                peakPOS = as.numeric(peakPOS),
                endPOS = as.numeric(endPOS),
                interval.var.exp  = as.numeric(interval.var.exp),
                Simulated.QTL.VarExp = as.numeric(Simulated.QTL.VarExp), 
                peak_id = as.numeric(peak_id),
                BETA = as.numeric(BETA),
                Effect = as.numeric(Effect),
                Frequency = as.numeric(Frequency),
                log10p = dplyr::if_else(Simulated == FALSE, true = interval.log10p, false = log10p), # false discoveries inherit the log10p value of the peak marker for the interval
                log10p = as.numeric(log10p),
                interval_size = as.numeric(interval_size),
                aboveBF = dplyr::case_when(aboveBF == 1 ~ TRUE, 
                                           aboveBF == 0 ~ FALSE,
                                           is.na(aboveBF) ~ TRUE), # false discoveries by definition exceed significance threshold
                aboveBF = as.factor(aboveBF)) %>%
  dplyr::filter(!c(Detected == FALSE & aboveBF == TRUE),
                CHROM != 7)
dat.group500.50.aggregate$nQTL <- factor(dat.group500.50.aggregate$nQTL, levels = c("1","5","10","25"))
dat.group500.50.aggregate$group.size <- as.factor(500)
dat.group500.50.aggregate$CI <- as.factor(50)
#####

# Combining iterations of grouping parameter and CI extension length
dat <- dat.group1000.150.aggregate %>%
  dplyr::full_join(., dat.group500.150.aggregate) %>%
  dplyr::full_join(., dat.group1000.50.aggregate) %>%
  dplyr::full_join(., dat.group500.50.aggregate)
dat$group.size <- factor(dat$group.size, levels = c(500,1000))
dat$CI <- factor(dat$CI, levels = c(50,150))

# Combining default setting simulations performed with different hard filtered vcfs
default.dat <- dat.group1000.150.aggregate %>%
  dplyr::full_join(., dat.group1000.150.aggregate.WI)
```

### NemaScan simulation performance was assessed with the following experimental parameters:
* ###### Number of Simulated QTL: ```r levels(as.factor(dat$nQTL))```
* ###### Sample Population(s): ```r levels(as.factor(dat$strain_set))```
* ###### Heritability(ies): ```r levels(as.factor(dat$h2))```
* ###### MAF(s): ```r levels(as.factor(dat$MAF))```
* ###### Number of Replicates per Regime: ```r max(as.numeric(dat$Rep))```
* ###### QTL Effect Range: ```r levels(as.factor(dat$effect_range))```

```{r simulated QTL locations, echo=FALSE, warning=FALSE}
h2.pal <- wes_palette("Darjeeling1", 4)[c(1,4,3,2)]
nQTL.pal <- wes_palette("Darjeeling2", 4)[c(3,1,4,2)]
options(dplyr.summarise.inform = FALSE)
dat.group1000.150.aggregate.WI %>%
  dplyr::filter(Simulated == TRUE,
                !duplicated(QTL),
                algorithm == "MIXED") %>%
  ggplot(mapping = aes(x = POS/1000000, y = Effect, fill = nQTL)) + 
  theme_bw() + 
  geom_point(shape = 21, alpha = 0.75) + 
  facet_grid(.~CHROM, drop = TRUE, scales = "free") + 
  scale_fill_manual(values = nQTL.pal) + 
  labs(x = "Genomic position (Mb)",
       y = "Causal QTL Effect",
       title = "Where were QTL Simulated?")

dat.group1000.150.aggregate.WI %>%
  dplyr::filter(Simulated == TRUE,
                !duplicated(QTL),
                algorithm == "MIXED") %>%
  ggplot(., mapping = aes(x = Frequency, fill = nQTL)) +
  theme_bw() + 
  geom_density() + 
  theme(legend.position = "top") + 
  facet_grid(.~nQTL, drop = TRUE, scales = "free") + 
  scale_fill_manual(values = nQTL.pal) + 
  xlim(c(0.05,0.5)) + 
  labs(x = "Minor Allele Frequency",
       y = "Frequency of Simulated QTL (Smoothed Density)")

dat.group1000.150.aggregate.WI %>%
  dplyr::filter(Simulated == TRUE,
                algorithm == "MIXED") %>%
  ggplot(., mapping = aes(x = Simulated.QTL.VarExp, fill = nQTL)) +
  theme_bw() + 
  geom_density() + 
  theme(legend.position = "top") + 
  facet_grid(nQTL~h2, drop = TRUE) + 
  scale_fill_manual(values = nQTL.pal) + 
  labs(x = "Variance Explained by Simulated Variants (%)",
       y = "Frequency of Simulated QTL (Smoothed Density)")

dat.group1000.150.aggregate.WI %>%
  dplyr::filter(Simulated == TRUE, Detected == TRUE,
                algorithm == "MIXED") %>%
  ggplot(., mapping = aes(x = interval.var.exp, fill = nQTL)) +
  theme_bw() + 
  geom_density() + 
  theme(legend.position = "top") + 
  facet_grid(nQTL~h2, drop = TRUE) + 
  scale_fill_manual(values = nQTL.pal) + 
  labs(x = "Realized Variance Explained by QTL Regions Containing Simulated Variants (%)",
       y = "Frequency of Simulated QTL (Smoothed Density)")

dat.group1000.150.aggregate.WI %>%
  dplyr::filter(Simulated == TRUE, Detected == TRUE,
                algorithm == "MIXED") %>%
  ggplot(., mapping = aes(x = Simulated.QTL.VarExp, y = interval.var.exp)) + 
  theme_bw() + 
  geom_point(alpha = 0.2) + 
  facet_grid(nQTL~h2, scales = "free") + 
  geom_abline(slope = 1) + 
  theme(panel.grid = element_blank(),
        legend.position = "top") + 
  labs(x = "Variance Explained by Simulated QTL (%)",
       y = "Realized Variance Explained by QTL Region (%)")

dat.group1000.150.aggregate.WI %>%
  dplyr::filter(Simulated == TRUE, Detected == TRUE,
                algorithm == "MIXED") %>%
  ggplot(., mapping = aes(x = Simulated.QTL.VarExp, y = interval.var.exp, colour = aboveBF)) + 
  theme_bw() + 
  geom_point(alpha = 0.2) + 
  facet_grid(nQTL~h2, scales = "free") + 
  geom_abline(slope = 1) + 
  theme(panel.grid = element_blank(),
        legend.position = "top") + 
  scale_colour_manual(values = c("darkgreen","black"), name = "Significant Marker Association") + 
  labs(x = "Variance Explained by Simulated QTL (%)",
       y = "Realized Variance Explained by QTL Region (%)")

dat.group1000.150.aggregate.WI %>%
  dplyr::filter(Simulated == TRUE, Detected == TRUE, aboveBF == TRUE,
                algorithm == "MIXED") %>%
  ggplot(., mapping = aes(x = Simulated.QTL.VarExp, y = interval.var.exp, colour = top.hit)) + 
  theme_bw() + 
  geom_point(alpha = 0.2) + 
  facet_grid(nQTL~h2, scales = "free") + 
  geom_abline(slope = 1) + 
  theme(panel.grid = element_blank(),
        legend.position = "top") + 
  scale_colour_manual(values = c("purple","black"), name = "Top Marker Association") + 
  labs(x = "Variance Explained by Simulated QTL (%)",
       y = "Realized Variance Explained by QTL Region (%)")

```

```{r default settings PR curve, echo=FALSE, fig.height=6, fig.width=9, warning=FALSE}
pr.curve <- dat.group1000.150.aggregate.WI %>%
  dplyr::group_by(h2, nQTL, algorithm) %>%
  yardstick::pr_curve(Simulated, log10p) %>%
  dplyr::filter(!is.infinite(.threshold))

ggplot(pr.curve, mapping = aes(x = recall, y = precision, colour = nQTL)) + 
  theme_bw() + 
  geom_path() +
  theme(strip.text = element_text(size = 8),
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        panel.grid.minor = element_blank()) +
  theme(legend.position = "top") + 
  scale_colour_brewer(palette = "OrRd", name = "Number of Supporting QTL") +
  facet_grid(h2~algorithm) + 
  labs(x = "Recall", y = "Precision")
```

```{r plots, echo=FALSE, warning=FALSE}
designations <- default.dat %>%
  dplyr::filter(algorithm == "MIXED") %>%
  droplevels() %>%
  dplyr::mutate(designation = case_when(Simulated == TRUE & Detected == TRUE & aboveBF == TRUE ~ "Detected.CV",
                                        Simulated == TRUE & Detected == FALSE & aboveBF == FALSE ~ "Missed.CV",
                                        Simulated == TRUE & Detected == TRUE & aboveBF == FALSE ~ "CV.Not.Significant.In.Interval",
                                        Simulated == FALSE & Detected == TRUE & aboveBF == TRUE ~ "False.Discovery")) %>%
  tidyr::separate(col = detected.peak,
                  into = c("peak.CHROM","peak.POS"), 
                  sep = ":", remove = F) %>%
  dplyr::mutate(QTL.v.peak = abs(as.numeric(POS)-as.numeric(peak.POS))) %>%
  dplyr::group_by(h2, algorithm, nQTL, designation, Rep, vcf) %>%
  dplyr::summarise(n = n()) %>%
  tidyr::pivot_wider(names_from = designation, values_from = n)
designations[is.na(designations)] <- 0
designations$Detected <- rowSums(designations[,6:9])

split.Power <- designations %>%
  dplyr::mutate(Simulated = as.numeric(as.character(nQTL)),
                Power = Detected.CV/Simulated,
                Artefact.Rate = False.Discovery/Detected,
                Detected.CV.NS.Rate = CV.Not.Significant.In.Interval/Detected) %>%
  dplyr::group_by(algorithm, h2, nQTL, vcf) %>%
  dplyr::summarise(mean.Power = mean(Power),
                   sd.Power = sd(Power)) %>%
  dplyr::mutate(b = mean.Power + sd.Power,
                a = mean.Power - sd.Power,
                nQTL = as.factor(nQTL),
                ymax = if_else(condition = b > 1, 
                             true = 1-mean.Power, 
                             false = sd.Power),
                ymin = if_else(condition = a < 0, 
                             true = (0-mean.Power)*-1, 
                             false = sd.Power)) %>%
  dplyr::select(-a,-b)

power.plot <- ggplot(split.Power, mapping = aes(x = nQTL, y = mean.Power, colour = h2, 
                          group = interaction(h2,algorithm))) +
  theme_bw() +
  geom_line(position=position_dodge(width=0.2)) +
  geom_point(position = position_dodge(width = 0.2)) +
  geom_errorbar(data = split.Power, 
                mapping = aes(y = mean.Power, ymax = mean.Power+ymax, ymin = mean.Power-ymin),
                width = 0.2,
                position=position_dodge(width=0.2)) +
  scale_colour_manual(values = h2.pal, name = expression(italic(h^2))) +
  facet_grid(.~vcf) + 
  ylim(c(0,1)) + 
  theme(strip.text = element_text(size = 8),
        legend.position = "top",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(x = "Number of Supporting QTL",
       y = "Power")

split.Artefact <- designations %>%
  dplyr::mutate(Simulated = as.numeric(as.character(nQTL)),
                Power = Detected.CV/Simulated,
                Artefact.Rate = False.Discovery/Detected,
                Detected.CV.NS.Rate = CV.Not.Significant.In.Interval/Detected) %>%
  dplyr::group_by(algorithm, h2, nQTL, vcf) %>%
  dplyr::summarise(mean.Artefact = mean(Artefact.Rate),
                   sd.Artefact.Rate = sd(Artefact.Rate)) %>%
  dplyr::mutate(b = mean.Artefact + sd.Artefact.Rate,
                a = mean.Artefact - sd.Artefact.Rate,
                nQTL = as.factor(nQTL),
                ymax = if_else(condition = b > 1, 
                             true = 1-mean.Artefact, 
                             false = sd.Artefact.Rate),
                ymin = if_else(condition = a < 0, 
                             true = (0-mean.Artefact)*-1, 
                             false = sd.Artefact.Rate)) %>%
  dplyr::select(-a,-b)


AR.plot <- ggplot(split.Artefact, mapping = aes(x = nQTL, y = mean.Artefact , colour = h2, 
                          group = interaction(h2,algorithm))) +
  theme_bw() +
  geom_line(position=position_dodge(width=0.2)) +
  geom_point(position = position_dodge(width = 0.2)) +
  geom_errorbar(data = split.Artefact, 
                mapping = aes(y = mean.Artefact , ymax = mean.Artefact +ymax, ymin = mean.Artefact -ymin),
                width = 0.2,
                position=position_dodge(width=0.2)) +
  scale_colour_manual(values = h2.pal, name = expression(italic(h^2))) +
  facet_grid(.~vcf) + 
  ylim(c(0,1)) + 
  theme(strip.text = element_text(size = 8),
        legend.position = "top",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(x = "Number of Supporting QTL",
       y = "Artefact Rate")

split.NS.CV <- designations %>%
  dplyr::mutate(Simulated = as.numeric(as.character(nQTL)),
                Power = Detected.CV/Simulated,
                Artefact.Rate = False.Discovery/Detected,
                Detected.CV.NS.Rate = CV.Not.Significant.In.Interval/Detected) %>%
  dplyr::group_by(algorithm, h2, nQTL, vcf) %>%
  dplyr::summarise(mean.NS.CV = mean(Detected.CV.NS.Rate),
                   sd.NS.CV = sd(Detected.CV.NS.Rate)) %>%
  dplyr::mutate(b = mean.NS.CV + sd.NS.CV,
                a = mean.NS.CV - sd.NS.CV,
                nQTL = as.factor(nQTL),
                ymax = if_else(condition = b > 1, 
                             true = 1-mean.NS.CV, 
                             false = sd.NS.CV),
                ymin = if_else(condition = a < 0, 
                             true = (0-mean.NS.CV)*-1, 
                             false = sd.NS.CV)) %>%
  dplyr::select(-a,-b)


NS.CV.plot <- ggplot(split.NS.CV, mapping = aes(x = nQTL, y = mean.NS.CV , colour = h2, 
                                                group = interaction(h2,algorithm))) +
  theme_bw() +
  geom_line(position=position_dodge(width=0.2)) +
  geom_point(position = position_dodge(width = 0.2)) +
  geom_errorbar(data = split.NS.CV, 
                mapping = aes(y = mean.NS.CV , ymax = mean.NS.CV +ymax, ymin = mean.NS.CV -ymin),
                width = 0.2,
                position=position_dodge(width=0.2)) +
  scale_colour_manual(values = h2.pal, name = expression(italic(h^2))) +
  ylim(c(0,1)) + 
  facet_grid(.~vcf) + 
  theme(strip.text = element_text(size = 8),
        legend.position = "top",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(x = "Number of Supporting QTL",
       y = "CV Tag Rate")



BC <- cowplot::plot_grid(AR.plot + theme(legend.position = "none"),
                   NS.CV.plot + theme(legend.position = "none"),
                   nrow = 1,
                   labels = c("B","C"), align = "hv", axis = "b")


plots <- cowplot::plot_grid(power.plot + theme(legend.position = "none"),
                            BC,
                            nrow = 2,
                            labels = c("A","",""), align = "b")

h2.legend <- cowplot::get_legend(power.plot)
legends <- cowplot::plot_grid(h2.legend, ncol = 1)
prelim.fig.2 <- cowplot::plot_grid(plots, 
                                   legends, 
                                   ncol = 1, 
                                   rel_heights = c(8,1))
ggsave(plot = prelim.fig.2, filename = "output/prelim.fig.2.FDsplit.png", height = 6, width = 8)
prelim.fig.2


## GROUPING + CI SUPPLEMENT
supp.pal <- wes_palette(name = "IsleofDogs1", 4)
designations.supp <- dat %>%
  dplyr::filter(algorithm == "MIXED") %>%
  droplevels() %>%
  dplyr::mutate(designation = case_when(Simulated == TRUE & Detected == TRUE & aboveBF == TRUE ~ "Detected.CV",
                                        Simulated == TRUE & Detected == FALSE & aboveBF == FALSE ~ "Missed.CV",
                                        Simulated == TRUE & Detected == TRUE & aboveBF == FALSE ~ "CV.Not.Significant.In.Interval",
                                        Simulated == FALSE & Detected == TRUE & aboveBF == TRUE ~ "False.Discovery")) %>%
  tidyr::separate(col = detected.peak,
                  into = c("peak.CHROM","peak.POS"), 
                  sep = ":", remove = F) %>%
  dplyr::mutate(QTL.v.peak = abs(as.numeric(POS)-as.numeric(peak.POS))) %>%
  dplyr::group_by(h2, algorithm, nQTL, group.size, CI, Rep, designation) %>%
  dplyr::summarise(n = n()) %>%
  tidyr::pivot_wider(names_from = designation, values_from = n)
designations.supp[is.na(designations.supp)] <- 0
designations.supp$Detected <- rowSums(designations.supp[,7:10])

split.Power.supp <- designations.supp %>%
  dplyr::mutate(Simulated = as.numeric(as.character(nQTL)),
                Power = Detected.CV/Simulated,
                Artefact.Rate = False.Discovery/Detected,
                Detected.CV.NS.Rate = CV.Not.Significant.In.Interval/Detected) %>%
  dplyr::group_by(algorithm, h2, nQTL, group.size, CI) %>%
  dplyr::summarise(mean.Power = mean(Power),
                   sd.Power = sd(Power)) %>%
  dplyr::mutate(b = mean.Power + sd.Power,
                a = mean.Power - sd.Power,
                nQTL = as.factor(nQTL),
                ymax = if_else(condition = b > 1, 
                             true = 1-mean.Power, 
                             false = sd.Power),
                ymin = if_else(condition = a < 0, 
                             true = (0-mean.Power)*-1, 
                             false = sd.Power)) %>%
  dplyr::select(-a,-b)
levels(split.Power.supp$nQTL) <- c("1 QTL","5 QTL","10 QTL","25 QTL")
levels(split.Power.supp$h2) <- paste("h2", levels(split.Power.supp$h2), sep = " = ")
levels(split.Power.supp$group.size) <- c("500bp QTL Groups","1kb QTL Groups")


power.supp.plot <- split.Power.supp %>%
  ggplot(., mapping = aes(x = nQTL, y = mean.Power , colour = CI, 
                          group = interaction(algorithm,CI))) +
  theme_bw() +
  geom_line(position=position_dodge(width=0.2)) +
  geom_point(position = position_dodge(width = 0.2), alpha = 0.8) +
  geom_errorbar(data = split.Power.supp,
                mapping = aes(y = mean.Power , ymax = mean.Power +ymax, ymin = mean.Power -ymin),
                width = 0.2,
                position=position_dodge(width=0.2)) + 
  scale_colour_manual(values = supp.pal, name = "Marker Extension") +
  facet_grid(h2 ~ group.size) + 
  theme(strip.text = element_text(size = 8),
        legend.position = "top",
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  labs(x = "Number of Supporting QTL",
       y = "Power")

split.AF.supp <- designations.supp %>%
  dplyr::mutate(Simulated = as.numeric(as.character(nQTL)),
                Power = Detected.CV/Simulated,
                Artefact.Rate = False.Discovery/Detected,
                Detected.CV.NS.Rate = CV.Not.Significant.In.Interval/Detected) %>%
  dplyr::group_by(algorithm, h2, nQTL, group.size, CI) %>%
  dplyr::summarise(mean.Artefact.Rate = mean(Artefact.Rate),
                   sd.Artefact.Rate = sd(Artefact.Rate)) %>%
  dplyr::mutate(b = mean.Artefact.Rate + sd.Artefact.Rate,
                a = mean.Artefact.Rate - sd.Artefact.Rate,
                nQTL = as.factor(nQTL),
                ymax = if_else(condition = b > 1, 
                             true = 1-mean.Artefact.Rate, 
                             false = sd.Artefact.Rate),
                ymin = if_else(condition = a < 0, 
                             true = (0-mean.Artefact.Rate)*-1, 
                             false = sd.Artefact.Rate)) %>%
  dplyr::select(-a,-b)
levels(split.AF.supp$nQTL) <- c("1 QTL","5 QTL","10 QTL","25 QTL")
levels(split.AF.supp$h2) <- paste("h2", levels(split.AF.supp$h2), sep = " = ")
levels(split.AF.supp$group.size) <- c("500bp QTL Groups","1kb QTL Groups")

FDR.supp.plot <- split.AF.supp %>%
  ggplot(., mapping = aes(x = nQTL, y = mean.Artefact.Rate , colour = CI, 
                          group = interaction(algorithm,CI))) +
  theme_bw() +
  geom_line(position=position_dodge(width=0.2)) +
  geom_point(position = position_dodge(width = 0.2), alpha = 0.8) +
  geom_errorbar(data = split.AF.supp,
                mapping = aes(y = mean.Artefact.Rate , ymax = mean.Artefact.Rate +ymax, ymin = mean.Artefact.Rate -ymin),
                width = 0.2,
                position=position_dodge(width=0.2)) + 
  scale_colour_manual(values = supp.pal, name = "Marker Extension") +
  facet_grid(h2 ~ group.size) + 
  theme(strip.text = element_text(size = 8),
        legend.position = "top",
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  labs(x = "Number of Supporting QTL",
       y = "Artefact Rate")


split.CV.NS.supp <- designations.supp %>%
  dplyr::mutate(Simulated = as.numeric(as.character(nQTL)),
                Power = Detected.CV/Simulated,
                Artefact.Rate = False.Discovery/Detected,
                Detected.CV.NS.Rate = CV.Not.Significant.In.Interval/Detected) %>%
  dplyr::group_by(algorithm, h2, nQTL, group.size, CI) %>%
  dplyr::summarise(mean.Detected.CV.NS.Rate = mean(Detected.CV.NS.Rate),
                   sd.Detected.CV.NS.Rate = sd(Detected.CV.NS.Rate)) %>%
  dplyr::mutate(b = mean.Detected.CV.NS.Rate + sd.Detected.CV.NS.Rate,
                a = mean.Detected.CV.NS.Rate - sd.Detected.CV.NS.Rate,
                nQTL = as.factor(nQTL),
                ymax = if_else(condition = b > 1, 
                             true = 1-mean.Detected.CV.NS.Rate, 
                             false = sd.Detected.CV.NS.Rate),
                ymin = if_else(condition = a < 0, 
                             true = (0-mean.Detected.CV.NS.Rate)*-1, 
                             false = sd.Detected.CV.NS.Rate)) %>%
  dplyr::select(-a,-b)
levels(split.CV.NS.supp$nQTL) <- c("1 QTL","5 QTL","10 QTL","25 QTL")
levels(split.CV.NS.supp$h2) <- paste("h2", levels(split.CV.NS.supp$h2), sep = " = ")
levels(split.CV.NS.supp$group.size) <- c("500bp QTL Groups","1kb QTL Groups")

split.CV.NS.supp.plot <- split.CV.NS.supp %>%
  ggplot(., mapping = aes(x = nQTL, y = mean.Detected.CV.NS.Rate , colour = CI, 
                          group = interaction(algorithm,CI))) +
  theme_bw() +
  geom_line(position=position_dodge(width=0.2)) +
  geom_point(position = position_dodge(width = 0.2), alpha = 0.8) +
  geom_errorbar(data = split.CV.NS.supp,
                mapping = aes(y = mean.Detected.CV.NS.Rate , ymax = mean.Detected.CV.NS.Rate +ymax, ymin = mean.Detected.CV.NS.Rate -ymin),
                width = 0.2,
                position=position_dodge(width=0.2)) + 
  scale_colour_manual(values = supp.pal, name = "Marker Extension") +
  facet_grid(h2 ~ group.size) + 
  theme(strip.text = element_text(size = 8),
        legend.position = "top",
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  labs(x = "Number of Supporting QTL",
       y = "CV Tag Rate")



supp.plots.1 <- cowplot::plot_grid(power.supp.plot+ theme(legend.position = "none"),
                                   FDR.supp.plot + theme(legend.position = "none"),
                                   split.CV.NS.supp.plot + theme(legend.position = "none"),
                            nrow = 3,
                            labels = "AUTO", align = "b")

CI.legend <- cowplot::get_legend(power.supp.plot)
supp.legend <- cowplot::plot_grid(CI.legend, ncol = 1)
prelim.supp.fig.A <- cowplot::plot_grid(supp.plots.1, 
                                   supp.legend, 
                                   ncol = 1, 
                                   rel_heights = c(10,1))
ggsave(plot = prelim.supp.fig.A, filename = "output/prelim.supp.fig.A.FDsplit.png", height = 10, width = 5)
prelim.supp.fig.A



## ALGORITHM SUPPLEMENT
supp.pal.2 <- c("darkred","darkblue","purple")
designations <- dat.group1000.150.aggregate %>%
  dplyr::mutate(designation = case_when(Simulated == TRUE & Detected == TRUE & aboveBF == TRUE ~ "Detected.CV",
                                        Simulated == TRUE & Detected == FALSE & aboveBF == FALSE ~ "Missed.CV",
                                        Simulated == TRUE & Detected == TRUE & aboveBF == FALSE ~ "CV.Not.Significant.In.Interval",
                                        Simulated == FALSE & Detected == TRUE & aboveBF == TRUE ~ "False.Discovery")) %>%
  tidyr::separate(col = detected.peak,
                  into = c("peak.CHROM","peak.POS"), 
                  sep = ":", remove = F) %>%
  dplyr::mutate(QTL.v.peak = abs(as.numeric(POS)-as.numeric(peak.POS))) %>%
  dplyr::group_by(h2, algorithm, nQTL, designation, Rep) %>%
  dplyr::summarise(n = n()) %>%
  tidyr::pivot_wider(names_from = designation, values_from = n)
designations[is.na(designations)] <- 0
designations$Detected <- rowSums(designations[,5:8])
levels(designations$h2) <- paste("h2", levels(designations$h2), sep = " = ")

algo.split.Power <- designations %>%
  dplyr::mutate(Simulated = as.numeric(as.character(nQTL)),
                Power = Detected.CV/Simulated,
                Artefact.Rate = False.Discovery/Detected,
                Detected.CV.NS.Rate = CV.Not.Significant.In.Interval/Detected) %>%
  dplyr::group_by(algorithm, h2, nQTL) %>%
  dplyr::summarise(mean.Power = mean(Power),
                   sd.Power = sd(Power)) %>%
  dplyr::mutate(b = mean.Power + sd.Power,
                a = mean.Power - sd.Power,
                nQTL = as.factor(nQTL),
                ymax = if_else(condition = b > 1, 
                             true = 1-mean.Power, 
                             false = sd.Power),
                ymin = if_else(condition = a < 0, 
                             true = (0-mean.Power)*-1, 
                             false = sd.Power)) %>%
  dplyr::select(-a,-b)

algo.power.plot <- ggplot(algo.split.Power, mapping = aes(x = nQTL, y = mean.Power, colour = algorithm, 
                          group = algorithm)) +
  theme_bw() +
  geom_line(position=position_dodge(width=0.2)) +
  geom_point(position = position_dodge(width = 0.2), alpha = 0.8) +
  geom_errorbar(data = algo.split.Power,
                mapping = aes(y = mean.Power, ymax = mean.Power+ymax, ymin = mean.Power-ymin),
                width = 0.2,
                position=position_dodge(width=0.2)) + 
  scale_colour_manual(values = supp.pal.2, name = "Algorithm") +
  facet_grid(h2 ~ .) + 
  theme(strip.text = element_text(size = 8),
        legend.position = "top",
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  labs(x = "Number of Supporting QTL",
       y = "Power")



algo.split.AF <- designations %>%
  dplyr::mutate(Simulated = as.numeric(as.character(nQTL)),
                Power = Detected.CV/Simulated,
                Artefact.Rate = False.Discovery/Detected,
                Detected.CV.NS.Rate = CV.Not.Significant.In.Interval/Detected) %>%
  dplyr::group_by(algorithm, h2, nQTL) %>%
  dplyr::summarise(mean.Artefact.Rate = mean(Artefact.Rate),
                   sd.Artefact.Rate = sd(Artefact.Rate)) %>%
  dplyr::mutate(b = mean.Artefact.Rate + mean.Artefact.Rate,
                a = mean.Artefact.Rate - mean.Artefact.Rate,
                nQTL = as.factor(nQTL),
                ymax = if_else(condition = b > 1, 
                             true = 1-mean.Artefact.Rate, 
                             false = mean.Artefact.Rate),
                ymin = if_else(condition = a < 0, 
                             true = (0-mean.Artefact.Rate)*-1, 
                             false = mean.Artefact.Rate)) %>%
  dplyr::select(-a,-b)

algo.AF.plot <- ggplot(algo.split.AF, mapping = aes(x = nQTL, y = mean.Artefact.Rate, colour = algorithm, 
                          group = algorithm)) +
  theme_bw() +
  geom_line(position=position_dodge(width=0.2)) +
  geom_point(position = position_dodge(width = 0.2), alpha = 0.8) +
  geom_errorbar(data = algo.split.AF,
                mapping = aes(y = mean.Artefact.Rate, ymax = mean.Artefact.Rate+ymax, ymin = mean.Artefact.Rate-ymin),
                width = 0.2,
                position=position_dodge(width=0.2)) + 
  scale_colour_manual(values = supp.pal.2, name = "Algorithm") +
  facet_grid(h2 ~ .) + 
  theme(strip.text = element_text(size = 8),
        legend.position = "top",
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  labs(x = "Artefact Rate",
       y = "Power")




algo.split.CV.NS <- designations %>%
  dplyr::mutate(Simulated = as.numeric(as.character(nQTL)),
                Power = Detected.CV/Simulated,
                Artefact.Rate = False.Discovery/Detected,
                Detected.CV.NS.Rate = CV.Not.Significant.In.Interval/Detected) %>%
  dplyr::group_by(algorithm, h2, nQTL) %>%
  dplyr::summarise(mean.CV.NS = mean(Detected.CV.NS.Rate),
                   sd.CV.NS = sd(Detected.CV.NS.Rate)) %>%
  dplyr::mutate(b = mean.CV.NS + sd.CV.NS,
                a = mean.CV.NS - sd.CV.NS,
                nQTL = as.factor(nQTL),
                ymax = if_else(condition = b > 1, 
                             true = 1-mean.CV.NS, 
                             false = sd.CV.NS),
                ymin = if_else(condition = a < 0, 
                             true = (0-mean.CV.NS)*-1, 
                             false = sd.CV.NS)) %>%
  dplyr::select(-a,-b)

algo.CV.NS.plot <- ggplot(algo.split.CV.NS, mapping = aes(x = nQTL, y = mean.CV.NS, colour = algorithm, 
                          group = algorithm)) +
  theme_bw() +
  geom_line(position=position_dodge(width=0.2)) +
  geom_point(position = position_dodge(width = 0.2), alpha = 0.8) +
  geom_errorbar(data = algo.split.CV.NS,
                mapping = aes(y = mean.CV.NS, ymax = mean.CV.NS+ymax, ymin = mean.CV.NS-ymin),
                width = 0.2,
                position=position_dodge(width=0.2)) + 
  scale_colour_manual(values = supp.pal.2, name = "Algorithm") +
  facet_grid(h2 ~ .) + 
  theme(strip.text = element_text(size = 8),
        legend.position = "top",
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  labs(x = "CV Tag Rate",
       y = "Power")



supp.plots.2 <- cowplot::plot_grid(algo.power.plot+ theme(legend.position = "none"),
                                   algo.AF.plot + theme(legend.position = "none"),
                                   algo.CV.NS.plot + theme(legend.position = "none"),
                            nrow = 3,
                            labels = "AUTO", align = "b")

CI.legend <- cowplot::get_legend(algo.power.plot)
supp.legend.2 <- cowplot::plot_grid(CI.legend, ncol = 1)
prelim.supp.fig.B <- cowplot::plot_grid(supp.plots.2, 
                                   supp.legend.2, 
                                   ncol = 1, 
                                   rel_heights = c(10,1))
ggsave(plot = prelim.supp.fig.B, filename = "output/prelim.supp.fig.B.png", height = 10, width = 6.5)
prelim.supp.fig.B





options(scipen = 9999)
CV.NS.dist.from.peak <- dat.group1000.150.aggregate %>%
  dplyr::filter(algorithm == "MIXED") %>%
  droplevels() %>%
  dplyr::mutate(designation = case_when(Simulated == TRUE & Detected == TRUE & aboveBF == TRUE ~ "Detected.CV",
                                        Simulated == TRUE & Detected == FALSE & aboveBF == FALSE ~ "Missed.CV",
                                        Simulated == TRUE & Detected == TRUE & aboveBF == FALSE ~ "CV.Not.Significant.In.Interval",
                                        Simulated == FALSE & Detected == TRUE & aboveBF == TRUE ~ "False.Discovery")) %>%
  dplyr::filter(designation == "CV.Not.Significant.In.Interval") %>%
  tidyr::separate(col = detected.peak,
                  into = c("peak.CHROM","peak.POS"), 
                  sep = ":", remove = F) %>%
  dplyr::mutate(QTL.v.peak = as.numeric(POS)-as.numeric(peak.POS),
                pctile = ntile(QTL.v.peak, 10),
                most.data = as.factor(if_else(pctile %in% c(2:8), true = TRUE, false = FALSE)))
levels(CV.NS.dist.from.peak$nQTL) <- c("1 QTL","5 QTL","10 QTL","25 QTL")
CV.NS.dist.from.peak$most.data <- factor(CV.NS.dist.from.peak$most.data, levels = c("TRUE","FALSE"))

ggplot(data = CV.NS.dist.from.peak, aes(x = QTL.v.peak/1000000, y = Simulated.QTL.VarExp, colour = most.data)) + 
  theme_bw() + 
  geom_point(alpha = 0.15) + 
  facet_grid(h2 ~ nQTL, scales = "free", space = "free") + 
  scale_colour_manual(values = c("darkgreen","grey60"), name = "90% of all simulations") + 
  theme(legend.position = "top",
        panel.grid = element_blank()) + 
  labs(x = "Distance between undetected causal variant and peak marker (Mb)",
       y = "Variance explained by simulated QTL (%)")

dat.group1000.150.aggregate %>%
  dplyr::filter(algorithm == "MIXED") %>%
  droplevels() %>%
  dplyr::mutate(designation = case_when(Simulated == TRUE & Detected == TRUE & aboveBF == TRUE ~ "Detected.CV",
                                        Simulated == TRUE & Detected == FALSE & aboveBF == FALSE ~ "Missed.CV",
                                        Simulated == TRUE & Detected == TRUE & aboveBF == FALSE ~ "CV.Not.Significant.In.Interval",
                                        Simulated == FALSE & Detected == TRUE & aboveBF == TRUE ~ "False.Discovery")) %>%
  dplyr::filter(designation %in% c("CV.Not.Significant.In.Interval","False.Discovery")) %>% 
  dplyr::arrange(designation) %>%
  ggplot(., mapping = aes(x = interval.log10p, y = interval_size/1000000, colour = designation)) + 
  theme_bw() + 
  geom_point(alpha = 0.4) + 
  facet_grid(h2~nQTL)

```

## TABLES
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
options(dplyr.summarise.inform = FALSE)



# Which algorithm has greater power
print("POWER EVALUATION") # NOTE: WINNER HERE IS HIGHER
power.comp.algorithm <- dat %>%
  dplyr::group_by(h2, algorithm, nQTL, group.size, CI) %>%
  yardstick::sens(truth = Simulated, estimate = aboveBF) %>%
  dplyr::mutate(.metric = "Power") %>%
  tidyr::pivot_wider(names_from = algorithm, values_from = .estimate) %>%
  dplyr::select(-.metric, -.estimator) %>%
  dplyr::group_by(group.size, CI) %>%
  tidyr::nest()

for(i in 1:length(power.comp.algorithm$data)){
  print(paste0("Group Size: ", as.character(power.comp.algorithm$group.size[[i]])))
  print(paste0("CI Extension: ", as.character(power.comp.algorithm$CI[[i]])))
  print(power.comp.algorithm$data[[i]])
}

power.comp.group.size <- dat %>%
  dplyr::group_by(h2, algorithm, nQTL, group.size, CI) %>%
  yardstick::sens(truth = Simulated, estimate = Detected) %>%
  dplyr::mutate(.metric = "Power") %>%
  tidyr::pivot_wider(names_from = group.size, values_from = .estimate) %>%
  dplyr::mutate(grouping.diff = paste0(round((`1000`-`500`)*100, 2), "%")) %>%
  dplyr::select(-.metric, -.estimator) %>%
  dplyr::arrange(nQTL) %>%
  dplyr::group_by(algorithm, CI) %>%
  tidyr::nest()

for(i in 1:length(power.comp.group.size$data)){
  print(paste0("CI Extension: ", as.character(power.comp.group.size$CI[[i]])))
  print(paste0("Algorithm: ", as.character(power.comp.group.size$algorithm[[i]])))
  print(power.comp.group.size$data[[i]])
}

power.comp.CI <- dat %>%
  dplyr::group_by(h2, algorithm, nQTL, group.size, CI) %>%
  yardstick::sens(truth = Simulated, estimate = Detected) %>%
  dplyr::mutate(.metric = "Power") %>%
  tidyr::pivot_wider(names_from = CI, values_from = .estimate) %>%
  dplyr::mutate(CI.diff = paste0(round((`150`-`50`)*100, 2), "%")) %>%
  dplyr::select(-.metric, -.estimator) %>%
  dplyr::arrange(nQTL) %>%
  dplyr::group_by(algorithm, group.size) %>%
  tidyr::nest()

for(i in 1:length(power.comp.CI$data)){
  print(paste0("Group Size: ", as.character(power.comp.CI$group.size[[i]])))
  print(paste0("Algorithm: ", as.character(power.comp.CI$algorithm[[i]])))
  print(power.comp.CI$data[[i]])
}




print("FDR EVALUATION") # NOTE: WINNER HERE IS LOWER
FDR.comp.algorithm <- dat %>%
  dplyr::group_by(h2, algorithm, nQTL, group.size, CI) %>%
  yardstick::precision(truth = Simulated, estimate = Detected) %>%
  dplyr::select(-.metric, -.estimator) %>%
  dplyr::mutate(FDR = 1-.estimate) %>%
  dplyr::select(-.estimate) %>%
  dplyr::filter(!is.na(FDR)) %>%
  tidyr::pivot_wider(names_from = algorithm, values_from = FDR) %>%
  dplyr::group_by(group.size, CI) %>%
  tidyr::nest()

for(i in 1:length(FDR.comp.algorithm$data)){
  print(paste0("Group Size: ", as.character(FDR.comp.algorithm$group.size[[i]])))
  print(paste0("CI Extension: ", as.character(FDR.comp.algorithm$CI[[i]])))
  print(FDR.comp.algorithm$data[[i]])
}


FDR.comp.group.size <- dat %>%
  dplyr::group_by(h2, algorithm, nQTL, group.size, CI) %>%
  yardstick::precision(truth = Simulated, estimate = Detected) %>%
  dplyr::select(-.metric, -.estimator) %>%
  dplyr::mutate(FDR = 1-.estimate) %>%
  dplyr::select(-.estimate) %>%
  dplyr::filter(!is.na(FDR)) %>%
  tidyr::pivot_wider(names_from = group.size, values_from = FDR) %>%
  dplyr::mutate(grouping.diff = paste0(round((`1000`-`500`)*100, 2), "%")) %>%
  dplyr::group_by(algorithm, CI) %>%
  tidyr::nest()

for(i in 1:length(FDR.comp.group.size$data)){
  print(paste0("CI Extension: ", as.character(FDR.comp.group.size$CI[[i]])))
  print(paste0("Algorithm: ", as.character(FDR.comp.group.size$algorithm[[i]])))
  print(FDR.comp.group.size$data[[i]])
}

FDR.comp.CI <- dat %>%
  dplyr::group_by(h2, algorithm, nQTL, group.size, CI) %>%
  yardstick::precision(truth = Simulated, estimate = Detected) %>%
  dplyr::select(-.metric, -.estimator) %>%
  dplyr::mutate(FDR = 1-.estimate) %>%
  dplyr::select(-.estimate) %>%
  dplyr::filter(!is.na(FDR)) %>%
  tidyr::pivot_wider(names_from = CI, values_from = FDR) %>%
  dplyr::mutate(CI.diff = paste0(round((`150`-`50`)*100, 2), "%")) %>%
  dplyr::group_by(algorithm, group.size) %>%
  tidyr::nest()

for(i in 1:length(FDR.comp.CI$data)){
  print(paste0("Group Size: ", as.character(FDR.comp.CI$group.size[[i]])))
  print(paste0("Algorithm: ", as.character(FDR.comp.CI$algorithm[[i]])))
  print(FDR.comp.CI$data[[i]])
}

```

